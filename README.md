# SignToLearn


SignToLearn - A project that uses AI and computer vision to recognize American Sign Language (ASL) hand gestures in real time. This application uses MediaPipe for hand tracking and TensorFlow for ASL gesture recognition. The goal is to help users learn ASL in an interactive way similar to Duolingo
## Installation

Install my-project with npm

```bash
  npm install my-project
  cd my-project
```
npm (for React setup):
```bash
npm install npm@latest -g

```
Clone the repo:
```bash
git clone https://github.com/github_username/SignToLearn.git
```
Backend Setup (Flask):
```bash
cd SignToLearn/aslProject-front
```
Set up a virtual environment:
```bash
python3 -m venv venv
```

On Windows
```bash
.\venv\Scripts\activate
```
On macOS/Linux:
```bash
source venv/bin/activate
```
Install backend dependencies:
```bash
pip install -r requirements.txt
```
Start the Flask server:
```bash
python app.py
```
Navigate to the frontend directory:
```bash
cd SignToLearn/aslProject-front
```
Install frontend dependencies:
```bash
npm install
```
Start the React development server:
```bash
npm run dev
```

    
## Acknowledgements


## Authors

- [@jonathankoshy](https://github.com/JJKSweaty)
- [@afeefsyed](https://github.com/afeefsyedd)

- [@harrisahmed](https://github.com/Astone7500)

- [@mahadkhan](https://github.com/mahadk28)


## Built with

- [Flask](https://flask.palletsprojects.com/) - Backend web framework
- [TensorFlow](https://www.tensorflow.org/) - Machine learning framework
- [Keras](https://keras.io/) - High-level neural networks API
- [MediaPipe](https://mediapipe.dev/) - Framework for building multimodal applied ML pipelines
- [React](https://reactjs.org/) - JavaScript library for building user interfaces
- [OpenCV](https://opencv.org/) - Computer vision library
- [Axios](https://axios-http.com/) - Promise-based HTTP client for the browser and Node.js



